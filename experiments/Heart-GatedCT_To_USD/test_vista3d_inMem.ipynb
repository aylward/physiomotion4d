{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30066e92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T07:25:43.179447Z",
     "iopub.status.busy": "2026-01-30T07:25:43.179447Z",
     "iopub.status.idle": "2026-01-30T07:25:44.868390Z",
     "shell.execute_reply": "2026-01-30T07:25:44.866770Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def vista3d_inference_from_itk(\n",
    "    itk_image,\n",
    "    label_prompt=None,\n",
    "    points=None,\n",
    "    point_labels=None,\n",
    "    device=None,\n",
    "    bundle_path=None,\n",
    "    model_cache_dir=None,\n",
    "):\n",
    "    # 1. Import dependencies\n",
    "    import itk\n",
    "    from monai.bundle import download\n",
    "    from monai.data.itk_torch_bridge import itk_image_to_metatensor\n",
    "    from monai.inferers import sliding_window_inference\n",
    "    from monai.networks.nets import vista3d132\n",
    "    from monai.transforms import (\n",
    "        CropForeground,\n",
    "        EnsureChannelFirst,\n",
    "        EnsureType,\n",
    "        ScaleIntensityRange,\n",
    "        Spacing,\n",
    "    )\n",
    "    from monai.utils import set_determinism\n",
    "\n",
    "    set_determinism(seed=42)\n",
    "    if device is None:\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # 2. Handle \"no prompts\" case: segment all classes\n",
    "    if label_prompt is None and points is None:\n",
    "        everything_labels = list(\n",
    "            set([i + 1 for i in range(132)]) - set([2, 16, 18, 20, 21, 23, 24, 25, 26])\n",
    "        )\n",
    "        label_prompt = everything_labels\n",
    "        print(\n",
    "            f\"No prompt provided. Using everything_labels for {len(everything_labels)} classes.\"\n",
    "        )\n",
    "\n",
    "    if points is not None and point_labels is None:\n",
    "        raise ValueError(\"point_labels must be provided when points are specified\")\n",
    "\n",
    "    # 3. Download model bundle if needed\n",
    "    if bundle_path is None:\n",
    "        import tempfile\n",
    "\n",
    "        if model_cache_dir is None:\n",
    "            model_cache_dir = tempfile.mkdtemp()\n",
    "        try:\n",
    "            download(name=\"vista3d\", bundle_dir=model_cache_dir, source=\"monaihosting\")\n",
    "        except Exception:\n",
    "            download(name=\"vista3d\", bundle_dir=model_cache_dir, source=\"github\")\n",
    "        bundle_path = f\"{model_cache_dir}/vista3d\"\n",
    "\n",
    "    # 4. ITK->MetaTensor (in memory)\n",
    "    meta_tensor = itk_image_to_metatensor(\n",
    "        itk_image, channel_dim=None, dtype=torch.float32\n",
    "    )\n",
    "\n",
    "    input_size = itk_image.GetLargestPossibleRegion().GetSize()\n",
    "\n",
    "    # 5. Preprocessing pipeline\n",
    "    processed = meta_tensor\n",
    "    processed = EnsureChannelFirst(channel_dim=None)(processed)\n",
    "    processed = EnsureType(dtype=torch.float32)(processed)\n",
    "    processed = Spacing(pixdim=[1.5, 1.5, 1.5], mode=\"bilinear\")(processed)\n",
    "    processed = ScaleIntensityRange(\n",
    "        a_min=-1024, a_max=1024, b_min=0.0, b_max=1.0, clip=True\n",
    "    )(processed)\n",
    "    processed = CropForeground()(processed)\n",
    "\n",
    "    # 6. Load VISTA3D\n",
    "    model = vista3d132(encoder_embed_dim=48, in_channels=1)\n",
    "    model_path = f\"{bundle_path}/models/model.pt\"\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    # 7. Prepare input tensor\n",
    "    input_tensor = processed\n",
    "    if not isinstance(input_tensor, torch.Tensor):\n",
    "        input_tensor = torch.tensor(np.asarray(input_tensor), dtype=torch.float32)\n",
    "    if input_tensor.dim() == 3:\n",
    "        input_tensor = input_tensor.unsqueeze(0)\n",
    "    if input_tensor.dim() == 4:\n",
    "        input_tensor = input_tensor.unsqueeze(0)\n",
    "    input_tensor = input_tensor.to(device)\n",
    "\n",
    "    # 8. Prepare model inputs\n",
    "    model_inputs = {\"image\": input_tensor}\n",
    "    if label_prompt is not None:\n",
    "        label_prompt_tensor = torch.tensor(\n",
    "            label_prompt, dtype=torch.long, device=device\n",
    "        )\n",
    "        model_inputs[\"label_prompt\"] = label_prompt_tensor\n",
    "        print(\"label_prompt_tensor shape\", label_prompt_tensor.shape)\n",
    "    if points is not None:\n",
    "        point_coords = torch.tensor(\n",
    "            points, dtype=torch.float32, device=device\n",
    "        ).unsqueeze(0)\n",
    "        point_labels_tensor = torch.tensor(\n",
    "            point_labels, dtype=torch.float32, device=device\n",
    "        ).unsqueeze(0)\n",
    "        model_inputs[\"points\"] = point_coords\n",
    "        model_inputs[\"point_labels\"] = point_labels_tensor\n",
    "        print(\"point_coords shape\", point_coords.shape)\n",
    "\n",
    "    # 9. Sliding window inference for large images\n",
    "    def predictor_fn(x):\n",
    "        args = {k: v for k, v in model_inputs.items() if k != \"image\"}\n",
    "        print(x.shape)\n",
    "        return model(x, **args)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if any(dim > 128 for dim in input_tensor.shape[2:]):\n",
    "            print(\"Sliding window inference\")\n",
    "            output = sliding_window_inference(\n",
    "                input_tensor,\n",
    "                roi_size=[128, 128, 128],\n",
    "                sw_batch_size=1,\n",
    "                predictor=predictor_fn,\n",
    "                overlap=0.5,\n",
    "                mode=\"gaussian\",\n",
    "                device=device,\n",
    "            )\n",
    "        else:\n",
    "            print(\"Single window inference\")\n",
    "            output = model(\n",
    "                input_tensor, **{k: v for k, v in model_inputs.items() if k != \"image\"}\n",
    "            )\n",
    "\n",
    "    print(\"output shape\", output.shape)\n",
    "    # 10. Postprocess: multi-class to label map\n",
    "    output = output.cpu()\n",
    "    if hasattr(output, \"detach\"):\n",
    "        output = output.detach()\n",
    "    if isinstance(output, dict):\n",
    "        if \"pred\" in output:\n",
    "            output = output[\"pred\"]\n",
    "        else:\n",
    "            output = list(output.values())[0]\n",
    "\n",
    "    if output.shape[1] > 1:\n",
    "        label_map = torch.argmax(output, dim=1).squeeze(0).numpy().astype(np.uint16)\n",
    "    else:\n",
    "        label_map = (output > 0.5).squeeze(0).cpu().numpy().astype(np.uint8)\n",
    "\n",
    "    # Ensure output is zyx order for ITK\n",
    "    if label_map.shape != tuple(reversed(input_size)):\n",
    "        # Some transforms may flip axes; reorder as needed.\n",
    "        label_map_for_itk = np.transpose(label_map, axes=range(label_map.ndim)[::-1])\n",
    "    else:\n",
    "        label_map_for_itk = label_map\n",
    "\n",
    "    # ITK expects z,y,x ordering for GetImageFromArray\n",
    "    output_itk = itk.GetImageFromArray(label_map_for_itk)\n",
    "\n",
    "    # Return output in ITK format matching the input (size, spacing, origin, direction, type)\n",
    "    return output_itk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e5a477",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T07:25:44.870332Z",
     "iopub.status.busy": "2026-01-30T07:25:44.869712Z",
     "iopub.status.idle": "2026-01-30T07:25:56.909477Z",
     "shell.execute_reply": "2026-01-30T07:25:56.907477Z"
    }
   },
   "outputs": [],
   "source": [
    "import itk\n",
    "\n",
    "\n",
    "# Load an ITK image\n",
    "image = itk.imread(\"results/slice_fixed.mha\")\n",
    "\n",
    "spleen_segmentation = vista3d_inference_from_itk(\n",
    "    image, model_cache_dir=\"./network_weights\"\n",
    ")\n",
    "\n",
    "itk.imwrite(spleen_segmentation, \"results/slice_fixed.all_mask_vista3d_inMem.mha\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1db286c9d1b146749ee41e223f114dca": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "24e6acb9f38c4484a0395183243e2922": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1db286c9d1b146749ee41e223f114dca",
       "placeholder": "​",
       "style": "IPY_MODEL_86fba89c14c541b084ca788a47ff7659",
       "tabbable": null,
       "tooltip": null,
       "value": "Fetching 22 files: 100%"
      }
     },
     "2b30d6db4e9e4ca7af9604586daa3b81": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4e3ecbf102dd4bc7a674706e23f0cbe2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "86fba89c14c541b084ca788a47ff7659": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "96f98272868f419fbbad655457917984": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c7465905a44c46888f36b0ee14b7be93": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_24e6acb9f38c4484a0395183243e2922",
        "IPY_MODEL_d49926c8b1844d8f971dfe74aeb48c76",
        "IPY_MODEL_e8950a6331e44844a74926566196c3ec"
       ],
       "layout": "IPY_MODEL_4e3ecbf102dd4bc7a674706e23f0cbe2",
       "tabbable": null,
       "tooltip": null
      }
     },
     "cf948bf3f6a3402aa03d3983682e9ce9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d49926c8b1844d8f971dfe74aeb48c76": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_fad7bca382a34f0ea8d4a2a4c3c86f73",
       "max": 22.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2b30d6db4e9e4ca7af9604586daa3b81",
       "tabbable": null,
       "tooltip": null,
       "value": 22.0
      }
     },
     "e8950a6331e44844a74926566196c3ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_cf948bf3f6a3402aa03d3983682e9ce9",
       "placeholder": "​",
       "style": "IPY_MODEL_96f98272868f419fbbad655457917984",
       "tabbable": null,
       "tooltip": null,
       "value": " 22/22 [00:00&lt;00:00, 814.78it/s]"
      }
     },
     "fad7bca382a34f0ea8d4a2a4c3c86f73": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
