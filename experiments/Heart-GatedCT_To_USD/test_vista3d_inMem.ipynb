{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30066e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def vista3d_inference_from_itk(\n",
    "    itk_image,\n",
    "    label_prompt=None,\n",
    "    points=None,\n",
    "    point_labels=None,\n",
    "    device=None,\n",
    "    bundle_path=None,\n",
    "    model_cache_dir=None,\n",
    "):\n",
    "    # 1. Import dependencies\n",
    "    import itk\n",
    "    from monai.bundle import download\n",
    "    from monai.data.itk_torch_bridge import itk_image_to_metatensor\n",
    "    from monai.inferers import sliding_window_inference\n",
    "    from monai.networks.nets import vista3d132\n",
    "    from monai.transforms import (\n",
    "        CropForeground,\n",
    "        EnsureChannelFirst,\n",
    "        EnsureType,\n",
    "        ScaleIntensityRange,\n",
    "        Spacing,\n",
    "    )\n",
    "    from monai.utils import set_determinism\n",
    "\n",
    "    set_determinism(seed=42)\n",
    "    if device is None:\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # 2. Handle \"no prompts\" case: segment all classes\n",
    "    if label_prompt is None and points is None:\n",
    "        everything_labels = list(\n",
    "            set([i + 1 for i in range(132)]) - set([2, 16, 18, 20, 21, 23, 24, 25, 26])\n",
    "        )\n",
    "        label_prompt = everything_labels\n",
    "        print(\n",
    "            f\"No prompt provided. Using everything_labels for {len(everything_labels)} classes.\"\n",
    "        )\n",
    "\n",
    "    if points is not None and point_labels is None:\n",
    "        raise ValueError(\"point_labels must be provided when points are specified\")\n",
    "\n",
    "    # 3. Download model bundle if needed\n",
    "    if bundle_path is None:\n",
    "        import tempfile\n",
    "\n",
    "        if model_cache_dir is None:\n",
    "            model_cache_dir = tempfile.mkdtemp()\n",
    "        try:\n",
    "            download(name=\"vista3d\", bundle_dir=model_cache_dir, source=\"monaihosting\")\n",
    "        except Exception:\n",
    "            download(name=\"vista3d\", bundle_dir=model_cache_dir, source=\"github\")\n",
    "        bundle_path = f\"{model_cache_dir}/vista3d\"\n",
    "\n",
    "    # 4. ITK->MetaTensor (in memory)\n",
    "    meta_tensor = itk_image_to_metatensor(\n",
    "        itk_image, channel_dim=None, dtype=torch.float32\n",
    "    )\n",
    "\n",
    "    input_size = itk_image.GetLargestPossibleRegion().GetSize()\n",
    "\n",
    "    # 5. Preprocessing pipeline\n",
    "    processed = meta_tensor\n",
    "    processed = EnsureChannelFirst(channel_dim=None)(processed)\n",
    "    processed = EnsureType(dtype=torch.float32)(processed)\n",
    "    processed = Spacing(pixdim=[1.5, 1.5, 1.5], mode=\"bilinear\")(processed)\n",
    "    processed = ScaleIntensityRange(\n",
    "        a_min=-1024, a_max=1024, b_min=0.0, b_max=1.0, clip=True\n",
    "    )(processed)\n",
    "    processed = CropForeground()(processed)\n",
    "\n",
    "    # 6. Load VISTA3D\n",
    "    model = vista3d132(encoder_embed_dim=48, in_channels=1)\n",
    "    model_path = f\"{bundle_path}/models/model.pt\"\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    # 7. Prepare input tensor\n",
    "    input_tensor = processed\n",
    "    if not isinstance(input_tensor, torch.Tensor):\n",
    "        input_tensor = torch.tensor(np.asarray(input_tensor), dtype=torch.float32)\n",
    "    if input_tensor.dim() == 3:\n",
    "        input_tensor = input_tensor.unsqueeze(0)\n",
    "    if input_tensor.dim() == 4:\n",
    "        input_tensor = input_tensor.unsqueeze(0)\n",
    "    input_tensor = input_tensor.to(device)\n",
    "\n",
    "    # 8. Prepare model inputs\n",
    "    model_inputs = {\"image\": input_tensor}\n",
    "    if label_prompt is not None:\n",
    "        label_prompt_tensor = torch.tensor(\n",
    "            label_prompt, dtype=torch.long, device=device\n",
    "        )\n",
    "        model_inputs[\"label_prompt\"] = label_prompt_tensor\n",
    "        print(\"label_prompt_tensor shape\", label_prompt_tensor.shape)\n",
    "    if points is not None:\n",
    "        point_coords = torch.tensor(\n",
    "            points, dtype=torch.float32, device=device\n",
    "        ).unsqueeze(0)\n",
    "        point_labels_tensor = torch.tensor(\n",
    "            point_labels, dtype=torch.float32, device=device\n",
    "        ).unsqueeze(0)\n",
    "        model_inputs[\"points\"] = point_coords\n",
    "        model_inputs[\"point_labels\"] = point_labels_tensor\n",
    "        print(\"point_coords shape\", point_coords.shape)\n",
    "\n",
    "    # 9. Sliding window inference for large images\n",
    "    def predictor_fn(x):\n",
    "        args = {k: v for k, v in model_inputs.items() if k != \"image\"}\n",
    "        print(x.shape)\n",
    "        return model(x, **args)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if any(dim > 128 for dim in input_tensor.shape[2:]):\n",
    "            print(\"Sliding window inference\")\n",
    "            output = sliding_window_inference(\n",
    "                input_tensor,\n",
    "                roi_size=[128, 128, 128],\n",
    "                sw_batch_size=1,\n",
    "                predictor=predictor_fn,\n",
    "                overlap=0.5,\n",
    "                mode=\"gaussian\",\n",
    "                device=device,\n",
    "            )\n",
    "        else:\n",
    "            print(\"Single window inference\")\n",
    "            output = model(\n",
    "                input_tensor, **{k: v for k, v in model_inputs.items() if k != \"image\"}\n",
    "            )\n",
    "\n",
    "    print(\"output shape\", output.shape)\n",
    "    # 10. Postprocess: multi-class to label map\n",
    "    output = output.cpu()\n",
    "    if hasattr(output, \"detach\"):\n",
    "        output = output.detach()\n",
    "    if isinstance(output, dict):\n",
    "        if \"pred\" in output:\n",
    "            output = output[\"pred\"]\n",
    "        else:\n",
    "            output = list(output.values())[0]\n",
    "\n",
    "    if output.shape[1] > 1:\n",
    "        label_map = torch.argmax(output, dim=1).squeeze(0).numpy().astype(np.uint16)\n",
    "    else:\n",
    "        label_map = (output > 0.5).squeeze(0).cpu().numpy().astype(np.uint8)\n",
    "\n",
    "    # Ensure output is zyx order for ITK\n",
    "    if label_map.shape != tuple(reversed(input_size)):\n",
    "        # Some transforms may flip axes; reorder as needed.\n",
    "        label_map_for_itk = np.transpose(label_map, axes=range(label_map.ndim)[::-1])\n",
    "    else:\n",
    "        label_map_for_itk = label_map\n",
    "\n",
    "    # ITK expects z,y,x ordering for GetImageFromArray\n",
    "    output_itk = itk.GetImageFromArray(label_map_for_itk)\n",
    "\n",
    "    # Return output in ITK format matching the input (size, spacing, origin, direction, type)\n",
    "    return output_itk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e5a477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itk\n",
    "\n",
    "\n",
    "# Load an ITK image\n",
    "image = itk.imread(\"results/slice_fixed.mha\")\n",
    "\n",
    "spleen_segmentation = vista3d_inference_from_itk(\n",
    "    image, model_cache_dir=\"./network_weights\"\n",
    ")\n",
    "\n",
    "itk.imwrite(spleen_segmentation, \"results/slice_fixed.all_mask_vista3d_inMem.mha\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}